# -*- coding: utf-8 -*-
"""G-23.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AHArXuP63CgmaRcfZoCjDFbKFHUNx_cQ
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc
import seaborn as sns
import matplotlib.pyplot as plt

data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/data.csv')

print(data.head())

X = data.drop(columns=['Bankrupt?'])
y = data['Bankrupt?']

X.fillna(X.mean(), inplace=True)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

def evaluate_model(model, X_train_scaled, X_test_scaled, y_train, y_test):
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_test_scaled)
    accuracy = accuracy_score(y_test, y_pred)
    classification_rep = classification_report(y_test, y_pred)
    print(f"Model: {model.__class__.__name__}")
    print(f"Accuracy: {accuracy:.2f}")
    print("\nClassification Report:\n", classification_rep)
    print('-' * 60)
    return y_pred

logistic_regression_model = LogisticRegression(random_state=42)
y_pred_logistic = evaluate_model(logistic_regression_model, X_train_scaled, X_test_scaled, y_train, y_test)

random_forest_model = RandomForestClassifier(random_state=42)
y_pred_rf = evaluate_model(random_forest_model, X_train_scaled, X_test_scaled, y_train, y_test)

gradient_boosting_model = GradientBoostingClassifier(random_state=42)
y_pred_gb = evaluate_model(gradient_boosting_model, X_train_scaled, X_test_scaled, y_train, y_test)

xgboost_model = XGBClassifier(random_state=42)
y_pred_xgb = evaluate_model(xgboost_model, X_train_scaled, X_test_scaled, y_train, y_test)

svm_model = SVC(kernel='linear', random_state=42, probability=True)
y_pred_svm = evaluate_model(svm_model, X_train_scaled, X_test_scaled, y_train, y_test)

models = ['Logistic Regression', 'Random Forest', 'Gradient Boosting', 'XGBoost', 'SVM']
accuracies = [
    accuracy_score(y_test, y_pred_logistic),
    accuracy_score(y_test, y_pred_rf),
    accuracy_score(y_test, y_pred_gb),
    accuracy_score(y_test, y_pred_xgb),
    accuracy_score(y_test, y_pred_svm)
]

plt.figure(figsize=(10, 6))
plt.bar(models, accuracies, color='skyblue')
plt.title('Model Accuracy Comparison')
plt.xlabel('Models')
plt.ylabel('Accuracy')
plt.show()

conf_matrix = confusion_matrix(y_test, y_pred_rf)

def plot_confusion_matrix(y_test, y_pred, model_name):
    conf_matrix = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(6, 4))
    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
    plt.title(f'{model_name} Confusion Matrix')
    plt.ylabel('Actual Label')
    plt.xlabel('Predicted Label')
    plt.show()

# Logistic Regression
plot_confusion_matrix(y_test, y_pred_logistic, "Logistic Regression")

# Random Forest
plot_confusion_matrix(y_test, y_pred_rf, "Random Forest")

# Gradient Boosting
plot_confusion_matrix(y_test, y_pred_gb, "Gradient Boosting")

# XGBoost
plot_confusion_matrix(y_test, y_pred_xgb, "XGBoost")

# SVM
plot_confusion_matrix(y_test, y_pred_svm, "SVM")

plt.figure(figsize=(10, 8))

y_prob_logistic = logistic_regression_model.predict_proba(X_test_scaled)[:, 1]
fpr_logistic, tpr_logistic, _ = roc_curve(y_test, y_prob_logistic)
roc_auc_logistic = auc(fpr_logistic, tpr_logistic)
plt.plot(fpr_logistic, tpr_logistic, label=f'Logistic Regression (AUC = {roc_auc_logistic:.2f})')

y_prob_rf = random_forest_model.predict_proba(X_test_scaled)[:, 1]
fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf)
roc_auc_rf = auc(fpr_rf, tpr_rf)
plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {roc_auc_rf:.2f})')

y_prob_gb = gradient_boosting_model.predict_proba(X_test_scaled)[:, 1]
fpr_gb, tpr_gb, _ = roc_curve(y_test, y_prob_gb)
roc_auc_gb = auc(fpr_gb, tpr_gb)
plt.plot(fpr_gb, tpr_gb, label=f'Gradient Boosting (AUC = {roc_auc_gb:.2f})')

y_prob_xgb = xgboost_model.predict_proba(X_test_scaled)[:, 1]
fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_prob_xgb)
roc_auc_xgb = auc(fpr_xgb, tpr_xgb)
plt.plot(fpr_xgb, tpr_xgb, label=f'XGBoost (AUC = {roc_auc_xgb:.2f})')

y_prob_svm = svm_model.predict_proba(X_test_scaled)[:, 1]
fpr_svm, tpr_svm, _ = roc_curve(y_test, y_prob_svm)
roc_auc_svm = auc(fpr_svm, tpr_svm)
plt.plot(fpr_svm, tpr_svm, label=f'SVM (AUC = {roc_auc_svm:.2f})')

importances = random_forest_model.feature_importances_
indices = np.argsort(importances)[::-1]

plt.figure(figsize=(10, 6))
plt.title("Feature Importances (Random Forest)")
plt.bar(range(X_train.shape[1]), importances[indices], color="b", align="center")
plt.xticks(range(X_train.shape[1]), X.columns[indices], rotation=90)
plt.tight_layout()
plt.show()

most_important_feature = X.columns[indices[0]]
print(f"Most Important Feature: {most_important_feature}")
data['Most_Important_Feature'] = X[most_important_feature]

plt.figure(figsize=(10, 6))
sns.scatterplot(data=data, x='Most_Important_Feature', y='Bankrupt?', hue='Bankrupt?', palette='coolwarm', alpha=0.7)
plt.title(f'{most_important_feature} vs Bankruptcy Status')
plt.xlabel(most_important_feature)
plt.ylabel('Bankruptcy Status')
plt.legend(title='Bankrupt?')
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(data=data, x='Bankrupt?', y='Most_Important_Feature', palette='coolwarm')
plt.title(f'Distribution of {most_important_feature} by Bankruptcy Status')
plt.xlabel('Bankruptcy Status')
plt.ylabel(most_important_feature)
plt.show()

plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
sns.histplot(data[data['Bankrupt?'] == 0], x='Most_Important_Feature', bins=30, color='blue', kde=True)
plt.title(f'Histogram of {most_important_feature} (Non-Bankrupt)')

plt.subplot(1, 2, 2)
sns.histplot(data[data['Bankrupt?'] == 1], x='Most_Important_Feature', bins=30, color='red', kde=True)
plt.title(f'Histogram of {most_important_feature} (Bankrupt)')

plt.tight_layout()
plt.show()

new_company_data = [[0.474040852	,0.533307894	,0.523689705	,0.600577985	,0.600577985	,0.998967008	,0.797368294	,0.809299293	,0.303491655	,0.781550887	,0.000113786	,917000000	,0.467198443	,0.000709071	,0	,0.171547765	,0.171547765	,0.171547765	,0.212914815	,0.32231025	,0.025711995,	0.096001954	,0.168863448	,0.022131735	,0.848178819	,0.689652794	,0.689652794	,0.217619855	,6160000000	,0.000442092	,0.264174651,	0.382670169	,0.010100437	,0.006446767	,0.640422734	,0.005155072	,0.10656952	,0.89343048	,0.005195922	,0.37315107	,0.006498611	,0.095958116	,0.167860644	,0.399927387	,0.145427286	,0.001237661	,0.005112353	,0.000106619	,0.00017929	,0.033709677	,0.026118121	,0.392494516	,0.018191851	,0.791909627	,0.248973745	,0.371121251	,0.074169857	,0.006590766	,0.005663643	,0.069166166	,0.351351763	,0.277413791	,0.009413662	,0.607048583	,0.734591205	,0.329035251	,0.004786619	,0.930763203	,0.00221748	,0.024483556	,9230000000	,6330000000	,0.593944043	,5470000000	,0.671579757	,0.412271984	,0.607048583	,0.329035251,	0.11357108	,0.656022847	,0.462370532	,0.60190049	,0.316477361	,0.028901672	,0	,0.794157853	,0.005262223	,0.623776799	,0.600577558	,0.839910497,	0.278517753	,0.02499974	,0.577445287	,1	,0.035464109]]

new_company_scaled = scaler.transform(new_company_data)

def predict_bankruptcy(model, new_company_scaled):
    bankruptcy_prediction = model.predict(new_company_scaled)
    return 'Bankrupt' if bankruptcy_prediction[0] == 1 else 'Not Bankrupt'

models = {
    "Logistic Regression": logistic_regression_model,
    "Random Forest": random_forest_model,
    "Gradient Boosting": gradient_boosting_model,
    "XGBoost": xgboost_model,
    "SVM": svm_model
}

predictions = {}
for model_name, model in models.items():
    prediction = predict_bankruptcy(model, new_company_scaled)
    predictions[model_name] = prediction
    print(f"{model_name}: Bankruptcy Prediction for new company: {prediction}")

accuracies = {
    "Logistic Regression": accuracy_score(y_test, y_pred_logistic),
    "Random Forest": accuracy_score(y_test, y_pred_rf),
    "Gradient Boosting": accuracy_score(y_test, y_pred_gb),
    "XGBoost": accuracy_score(y_test, y_pred_xgb),
    "SVM": accuracy_score(y_test, y_pred_svm)
}

best_model_name = max(accuracies, key=accuracies.get)
best_model_accuracy = accuracies[best_model_name]

print("\n--- Model Comparison ---")
print("Model Accuracy Scores:")
for model_name, accuracy in accuracies.items():
    print(f"{model_name}: {accuracy:.2f}")

print(f"\nThe best model is {best_model_name} with an accuracy of {best_model_accuracy:.2f}")

best_model_prediction = predictions[best_model_name]
print(f"\nThe best model's prediction for the new company: {best_model_prediction}")